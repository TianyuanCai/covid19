{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_path = '../data/raw/'\n",
    "processed_path = '../data/processed/'\n",
    "raw_path = '../data/raw/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mobility(processed:pd.DataFrame, mobility:pd.DataFrame):\n",
    "    \n",
    "    '''\n",
    "    processed: old time_series data\n",
    "    mobility: new mobility csv from Google\n",
    "    '''\n",
    "    \n",
    "    # clean mobility data\n",
    "    USA = mobility.loc[mobility['country_region'] == 'United States'].reset_index()\n",
    "    to_drop = ['index', 'country_region_code', 'country_region']\n",
    "    USA = USA.drop(to_drop, axis=1)\n",
    "    USA.insert(1, 'county', USA['sub_region_2'].str.lower())\n",
    "    USA = USA.drop(['sub_region_2'],axis=1)\n",
    "    USA['county'].loc[(USA['sub_region_1'] == 'District of Columbia')] = 'District of Columbia'\n",
    "    USA = USA.loc[~pd.isna(USA['county'])]\n",
    "    USA['county'] = USA['county'].map(lambda x: re.sub(' county| city','', x)).str.lower()\n",
    "    USA.insert(1, 'state', USA['sub_region_1'].str.lower())\n",
    "    USA = USA.drop(['sub_region_1'],axis=1)\n",
    "    \n",
    "    # prepare old time series data\n",
    "    processed['county'] = processed['county'].str.lower()\n",
    "    processed['state'] = processed['state'].str.lower()\n",
    "    \n",
    "    # take only subset of counties according to proccessed data\n",
    "    counties = pd.unique(processed['county'].str.lower().map(lambda x: re.sub(' city','', x)))\n",
    "    USA = USA.loc[USA['county'].str.lower().isin(counties)]\n",
    "    \n",
    "    # deal with duplicates\n",
    "    columns = set(USA.columns) - set(['state', 'county', 'date'])\n",
    "    agg = {key:'mean' for key in columns}\n",
    "    USA_grouped = USA.groupby(['state', 'county', 'date']).aggregate(agg)\n",
    "    \n",
    "    df = pd.merge(processed,USA_grouped, on=['date','county', 'state'], how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = update_mobility(processed, mobility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility = pd.read_csv(mobility_path+'Global_Mobility_Report.csv', low_memory=False)\n",
    "processed = pd.read_csv(processed_path + 'time_series.csv')\n",
    "zips = pd.read_csv(raw_path + 'uszips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only subset of counties according to proccessed data\n",
    "counties = pd.unique(processed['county'].str.lower().map(lambda x: re.sub(' city','', x)))\n",
    "USA = USA.loc[USA['county'].str.lower().isin(counties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in counties\n",
    "difference = set(pd.unique(counties)) - set(USA['county'].str.lower().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut time\n",
    "# USA = USA.loc[USA['date']<'2020-04-23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with duplicates\n",
    "columns = set(USA.columns) - set(['state', 'county', 'date'])\n",
    "agg = {key:'mean' for key in columns}\n",
    "USA_grouped = USA.groupby(['state', 'county', 'date']).aggregate(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(processed,USA_grouped, on=['date','county', 'state'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(processed_path + 'time_series_mobility.csv',index=False)\n",
    "# df = pd.read_csv(processed_path + 'time_series_mobility.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>cldCvrMin</th>\n",
       "      <th>cldCvrAvg</th>\n",
       "      <th>cldCvrMax</th>\n",
       "      <th>dewPtMin</th>\n",
       "      <th>...</th>\n",
       "      <th>wetBulbAvg</th>\n",
       "      <th>wetBulbMax</th>\n",
       "      <th>first_date</th>\n",
       "      <th>days_since_10_cases</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>snohomish</td>\n",
       "      <td>washington</td>\n",
       "      <td>53061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>...</td>\n",
       "      <td>42.7</td>\n",
       "      <td>44.1</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>-44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>snohomish</td>\n",
       "      <td>washington</td>\n",
       "      <td>53061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>...</td>\n",
       "      <td>42.4</td>\n",
       "      <td>44.6</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>-43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>snohomish</td>\n",
       "      <td>washington</td>\n",
       "      <td>53061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>...</td>\n",
       "      <td>48.6</td>\n",
       "      <td>50.7</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>-42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>snohomish</td>\n",
       "      <td>washington</td>\n",
       "      <td>53061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>43.9</td>\n",
       "      <td>...</td>\n",
       "      <td>46.7</td>\n",
       "      <td>48.3</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>-41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>snohomish</td>\n",
       "      <td>washington</td>\n",
       "      <td>53061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>...</td>\n",
       "      <td>44.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54946</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>saline</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>31151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>42.8</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54947</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>saline</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>31151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54948</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>saline</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>31151</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54949</th>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>saline</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>31151</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>...</td>\n",
       "      <td>45.3</td>\n",
       "      <td>55.4</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54950</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>saline</td>\n",
       "      <td>nebraska</td>\n",
       "      <td>31151</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>51.1</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54951 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     county       state   fips  cases  deaths  cldCvrMin  \\\n",
       "0      2020-01-21  snohomish  washington  53061      1       0        7.0   \n",
       "1      2020-01-22  snohomish  washington  53061      1       0       31.0   \n",
       "2      2020-01-23  snohomish  washington  53061      1       0       75.0   \n",
       "3      2020-01-24  snohomish  washington  53061      1       0       15.0   \n",
       "4      2020-01-25  snohomish  washington  53061      1       0       17.0   \n",
       "...           ...        ...         ...    ...    ...     ...        ...   \n",
       "54946  2020-04-15     saline    nebraska  31151      1       0        0.0   \n",
       "54947  2020-04-16     saline    nebraska  31151      3       0       45.0   \n",
       "54948  2020-04-17     saline    nebraska  31151      4       0        0.0   \n",
       "54949  2020-04-18     saline    nebraska  31151      6       0        0.0   \n",
       "54950  2020-04-19     saline    nebraska  31151      7       0        0.0   \n",
       "\n",
       "       cldCvrAvg  cldCvrMax  dewPtMin  ...  wetBulbAvg  wetBulbMax  \\\n",
       "0           71.0      100.0      37.4  ...        42.7        44.1   \n",
       "1           74.0      100.0      39.9  ...        42.4        44.6   \n",
       "2           93.0      100.0      44.3  ...        48.6        50.7   \n",
       "3           57.0       95.0      43.9  ...        46.7        48.3   \n",
       "4           72.0      100.0      41.4  ...        44.5        48.0   \n",
       "...          ...        ...       ...  ...         ...         ...   \n",
       "54946        1.0       12.0      17.4  ...        33.8        42.8   \n",
       "54947       88.0      100.0      22.7  ...        32.3        34.5   \n",
       "54948       35.0      100.0      23.9  ...        33.5        40.9   \n",
       "54949        9.0       69.0      30.1  ...        45.3        55.4   \n",
       "54950        8.0       99.0      31.3  ...        46.0        51.1   \n",
       "\n",
       "       first_date  days_since_10_cases  \\\n",
       "0      2020-03-05                  -44   \n",
       "1      2020-03-05                  -43   \n",
       "2      2020-03-05                  -42   \n",
       "3      2020-03-05                  -41   \n",
       "4      2020-03-05                  -40   \n",
       "...           ...                  ...   \n",
       "54946  2020-04-21                   -6   \n",
       "54947  2020-04-21                   -5   \n",
       "54948  2020-04-21                   -4   \n",
       "54949  2020-04-21                   -3   \n",
       "54950  2020-04-21                   -2   \n",
       "\n",
       "       residential_percent_change_from_baseline  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "...                                         ...   \n",
       "54946                                       NaN   \n",
       "54947                                       NaN   \n",
       "54948                                       NaN   \n",
       "54949                                       NaN   \n",
       "54950                                       NaN   \n",
       "\n",
       "       grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "54946                                                NaN   \n",
       "54947                                                NaN   \n",
       "54948                                                NaN   \n",
       "54949                                                NaN   \n",
       "54950                                                NaN   \n",
       "\n",
       "       transit_stations_percent_change_from_baseline  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "54946                                            NaN   \n",
       "54947                                            NaN   \n",
       "54948                                            NaN   \n",
       "54949                                            NaN   \n",
       "54950                                            NaN   \n",
       "\n",
       "       retail_and_recreation_percent_change_from_baseline  \\\n",
       "0                                                    NaN    \n",
       "1                                                    NaN    \n",
       "2                                                    NaN    \n",
       "3                                                    NaN    \n",
       "4                                                    NaN    \n",
       "...                                                  ...    \n",
       "54946                                                NaN    \n",
       "54947                                                NaN    \n",
       "54948                                                NaN    \n",
       "54949                                                NaN    \n",
       "54950                                                NaN    \n",
       "\n",
       "       parks_percent_change_from_baseline  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "...                                   ...   \n",
       "54946                                 NaN   \n",
       "54947                                 NaN   \n",
       "54948                                 NaN   \n",
       "54949                                 NaN   \n",
       "54950                                 NaN   \n",
       "\n",
       "       workplaces_percent_change_from_baseline  \n",
       "0                                          NaN  \n",
       "1                                          NaN  \n",
       "2                                          NaN  \n",
       "3                                          NaN  \n",
       "4                                          NaN  \n",
       "...                                        ...  \n",
       "54946                                      NaN  \n",
       "54947                                      NaN  \n",
       "54948                                      NaN  \n",
       "54949                                      NaN  \n",
       "54950                                      NaN  \n",
       "\n",
       "[54951 rows x 69 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility = pd.read_csv(mobility_file)\n",
    "agg_df = update_mobility(agg_df, mobility)\n",
    "\n",
    "income = pd.read_csv(income_file)\n",
    "agg_df = add_income(agg_df, income)\n",
    "\n",
    "population = pd.read_csv(population_file)\n",
    "agg_df = add_population(agg_df, population)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}